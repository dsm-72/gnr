{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granger Causality Operator\n",
    "\n",
    "> operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from sklearn.base import BaseEstimator\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from typing import Optional, ClassVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from atyp import SeriesLike, DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from gnr.static import (\n",
    "    LAG_ORDER, DEFAULT_TEST,\n",
    "\n",
    "    LOG2_FOLD, SIGNED_CORRELATION, STANDARD_SCALER, KNOWN_TRANSFORMS\n",
    ")\n",
    "\n",
    "from gnr.utils import (    \n",
    "    apply_log2_fold, apply_signed_correlation, apply_standard_scaler,\n",
    "    _prep_args_for_granger_causality_tests,\n",
    "    _prep_vars_for_granger_causality_tests\n",
    ")\n",
    "\n",
    "from gnr.fn import (\n",
    "    shift_trajectories, get_pval_from_granger_causality_tests, \n",
    "    grangers_causation_matrix, calculate_granger_causation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class GrangerCausality(BaseEstimator):\n",
    "    '''\n",
    "    Computes Granger Causality\n",
    "    Check Granger Causality of all possible combinations of the Time series.\n",
    "\n",
    "    The rows are the response variable, columns are predictors. The values in the table \n",
    "    are the P-Values. P-Values lesser than the significance level (0.05), implies \n",
    "    the Null Hypothesis that the coefficients of the corresponding past values is \n",
    "    zero, that is, the X does not cause Y can be rejected.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        Pandas DataFrame where rows are the response variable (features), and \n",
    "        columns are predictors (expression).\n",
    "    \n",
    "    x_vars : SeriesLike, optional\n",
    "        A subset of response variable (features) to compute granger's causality test with. \n",
    "        If not provided, defaults to `df.index.values` i.e. all rows in `df`.\n",
    "\n",
    "\n",
    "    y_vars : SeriesLike, optional\n",
    "        A subset of response variable (features) to compute granger's causality test with. \n",
    "        If not provided, defaults to `df.index.values` i.e. all rows in `df`.\n",
    "\n",
    "    shift : int, default=10\n",
    "        number to shift `df`'s values by\n",
    "\n",
    "    test : str, default='ssr_chi2test'\n",
    "        the kind of statistical test to use\n",
    "    \n",
    "    lag_order : int, default=1\n",
    "        how long to lag\n",
    "    \n",
    "    max_lag : tuple, optional\n",
    "        if `None` coerced to `(1, )`\n",
    "\n",
    "    n_jobs : int, default=-1\n",
    "        number of cpu threads to use during calculation\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    df_res : pd.DataFrame    \n",
    "        Pandas DataFrame with shape `(len(x_vars), len(y_vars))` containing the\n",
    "        minimum p-value from Granger's Causation Tests\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    If `x_var = ['A', B']` and `y_var = ['C', 'D]', the Granger's Causality matrix we\n",
    "    return has shape:\n",
    "    ```\n",
    "        | C_y | D_y |\n",
    "        -------------\n",
    "    | A_x |      |     |\n",
    "    --------------------\n",
    "    | B_x |      |     |\n",
    "\n",
    "    ```\n",
    "\n",
    "    See Also\n",
    "    --------\n",
    "    GrangerCausality._prep_args_for_granger_causality_tests :\n",
    "        validates input arguments\n",
    "\n",
    "    GrangerCausality._prep_vars_for_granger_causality_tests :\n",
    "        validates input variables\n",
    "    '''\n",
    "    _LOG2: ClassVar[str] = LOG2_FOLD\n",
    "    _SCOR: ClassVar[str] = SIGNED_CORRELATION\n",
    "    _STDN: ClassVar[str] = STANDARD_SCALER\n",
    "    KNOWN_TRANSFORMS: ClassVar[str] = KNOWN_TRANSFORMS\n",
    "\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        x_vars: Optional[SeriesLike] = None, \n",
    "        y_vars: Optional[SeriesLike] = None,\n",
    "        shift: Optional[int] = 10,\n",
    "        test: Optional[str] = DEFAULT_TEST,\n",
    "        lag_order: Optional[int] = LAG_ORDER,\n",
    "        max_lag: Optional[tuple] = (LAG_ORDER, ),\n",
    "        n_jobs: Optional[int] = -1\n",
    "    ):        \n",
    "        \n",
    "    \n",
    "\n",
    "        test, lag_order, max_lag = _prep_args_for_granger_causality_tests(test, lag_order, max_lag)\n",
    "\n",
    "        self.x_vars = x_vars\n",
    "        self.y_vars = y_vars\n",
    "        self.shift = shift\n",
    "        self.test = test\n",
    "        self.max_lag = max_lag\n",
    "        self.lag_order = lag_order\n",
    "        self.n_jobs = n_jobs\n",
    "\n",
    "        # original DataFrame\n",
    "        self.df_org = None\n",
    "\n",
    "        # results DataFrame\n",
    "        self.df_res = None\n",
    "        \n",
    "        # scalar if transforming\n",
    "        self.scaler = None\n",
    "\n",
    "    \n",
    "    def process_fit_params(self, **fit_params) -> dict:\n",
    "        '''\n",
    "        fit_params : dict, optional\n",
    "\n",
    "        NOTE: you can use either of the following. The first is more explicit, the second is more concise.\n",
    "        ```\n",
    "            {\n",
    "                \"apply\" : str, default=None | \"log2_fold\" | \"signed_correlation\" | \"standard_scaler\"\n",
    "            }\n",
    "\n",
    "            {\n",
    "                \"use_cached\" : bool, default=False\n",
    "                \"log2_fold\" : bool, default=False\n",
    "                \"signed_correlation\" : bool, default=False\n",
    "                \"standard_scaler\" : bool, default=False\n",
    "            }\n",
    "        ```\n",
    "        if `apply` is not `None`, then the following apply:\n",
    "        - `log2_fold` : will apply log2 fold change to `df_res`\n",
    "        - `signed_correlation` : will apply signed correlation to `df_res`\n",
    "        - `standard_scaler` : will apply standard scaler to `df_org` and `df_res`\n",
    "        '''\n",
    "        apply = fit_params.get('apply', None)\n",
    "        if apply is not None and apply not in self.KNOWN_TRANSFORMS:\n",
    "            if isinstance(apply, str):\n",
    "                for app in apply.split(' '):\n",
    "                    if app not in self.KNOWN_TRANSFORMS:\n",
    "                        continue\n",
    "                    fit_params[app] = True\n",
    "        return fit_params\n",
    "\n",
    "\n",
    "\n",
    "    def fit(self, X):\n",
    "        '''\n",
    "        Update internal parameters prior to computation in `transform`\n",
    "        '''\n",
    "        test, lag_order, max_lag = _prep_args_for_granger_causality_tests(self.test, self.lag_order, self.max_lag)\n",
    "        X, x_vars, y_vars = _prep_vars_for_granger_causality_tests(X, self.x_vars, self.y_vars, do_safety_check=True)\n",
    "        self.test = test\n",
    "        self.lag_order = lag_order\n",
    "        self.max_lag = max_lag\n",
    "        self.x_vars = x_vars\n",
    "        self.y_vars = y_vars\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X: DataFrame, y = None, **fit_params):   \n",
    "        # Save input DataFrame\n",
    "        self.df_org = X.copy()\n",
    "        fit_params = self.process_fit_params(**fit_params)\n",
    "\n",
    "        # Apply standard scaler\n",
    "        stdn = fit_params.get(self._STDN, False)\n",
    "        if stdn:\n",
    "            self.apply_standard_scaler(X)\n",
    "\n",
    "        # Use saved results\n",
    "        use_cached = fit_params.get('use_cached', False)\n",
    "        if use_cached and self.df_res is not None:\n",
    "            df_res = self.df_res.copy()\n",
    "\n",
    "        else:\n",
    "            df_res = calculate_granger_causation(\n",
    "                X, x_vars=self.x_vars, y_vars=self.y_vars,\n",
    "                shift=self.shift, test=self.test, \n",
    "                lag_order=self.lag_order, max_lag=self.max_lag,    \n",
    "                n_jobs=self.n_jobs\n",
    "            )\n",
    "\n",
    "        # Store results\n",
    "        self.df_res = df_res.copy()\n",
    "\n",
    "        log2 = fit_params.get(self._LOG2, False)\n",
    "        if log2:\n",
    "            df_res = apply_log2_fold(df_res)\n",
    "\n",
    "        scor = fit_params.get(self._SCOR, False)\n",
    "        if scor:\n",
    "            df_res = apply_signed_correlation(X, df_res)        \n",
    "\n",
    "        return df_res\n",
    "    \n",
    "    def fit_transform(self, X: DataFrame, y = None, **fit_params):\n",
    "        df_res = self.fit(X).transform(X, y = y, **fit_params)\n",
    "        return df_res\n",
    "    \n",
    "    def apply_log2_fold(self, df: DataFrame) -> DataFrame:\n",
    "        return apply_log2_fold(df)\n",
    "\n",
    "    def apply_signed_correlation(self, df_tseries: DataFrame, df_granger: DataFrame) -> pd.DataFrame:\n",
    "        return apply_signed_correlation(df_tseries, df_granger)\n",
    "    \n",
    "    def apply_standard_scaler(self, df: DataFrame) -> DataFrame:\n",
    "        df_res, scaler = apply_standard_scaler(df, return_scaler=True)\n",
    "        self.scaler = scaler\n",
    "        return df_res\n",
    "    \n",
    "    def invert_scaler(self, df: DataFrame) -> DataFrame:\n",
    "        if self.scaler is None:\n",
    "            raise ValueError\n",
    "        return self.scaler.inverse_transform(df)\n",
    "    \n",
    "    def plot_df_org(self, show_all_yticks: bool = True, **kwargs):\n",
    "        '''\n",
    "        Returns\n",
    "        -------\n",
    "        fig : matplotlib.pyplot.Figure\n",
    "        ax : matplotlib.pyplot.Axis\n",
    "        ClusterMap : seaborn.ClusterMap\n",
    "        '''\n",
    "        options = dict(cmap='inferno', robust=True, col_cluster=False, yticklabels=show_all_yticks)\n",
    "        options.update(kwargs)\n",
    "        cstrmp = sns.clustermap(self.df_org, **options)\n",
    "        return cstrmp\n",
    "    \n",
    "    def plot_df_res(self, show_all_yticks: bool = True, **kwargs):\n",
    "        '''\n",
    "        Returns\n",
    "        -------\n",
    "        fig : matplotlib.pyplot.Figure\n",
    "        ax : matplotlib.pyplot.Axis\n",
    "        ClusterMap : seaborn.ClusterMap\n",
    "        '''           \n",
    "        options = dict(yticklabels=show_all_yticks)\n",
    "        options.update(kwargs)\n",
    "        cstrmp = sns.clustermap(self.df_res, **options)\n",
    "        return cstrmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
